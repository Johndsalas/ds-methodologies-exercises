{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Fit the logistic regression classifier to your training sample and transform, \n",
    "i.e. make predictions on the training sample\n",
    "\n",
    "2 Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "3 Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, \n",
    "false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "4 Look in the scikit-learn documentation to research the solver parameter. \n",
    "What is your best option(s) for the particular problem you are trying to solve and the data to be used?\n",
    "\n",
    "5 Run through steps 2-4 using another solver (from question 5)\n",
    "Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#modeling imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from acquire import get_iris_data\n",
    "from prepare import prep_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Fit the logistic regression classifier to your training sample and transform, \n",
    "#i.e. make predictions on the training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import and clean iris data\n",
    "df = prep_iris(get_iris_data())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 70/30 train/test groups for x and y\n",
    "x=df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y=df[['species']]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.30,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit logistic regression clasifier onto training samples and transform\n",
    "logit=LogisticRegression(C=1,class_weight='balanced',random_state=123,solver='saga')\n",
    "logit.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.06581048e-03, 2.85360763e-01, 7.13573426e-01],\n",
       "       [1.07334021e-03, 2.41758386e-01, 7.57168273e-01],\n",
       "       [1.88099190e-02, 6.48735010e-01, 3.32455071e-01],\n",
       "       [8.64033177e-01, 1.35935117e-01, 3.17061926e-05],\n",
       "       [7.65439950e-01, 2.34438034e-01, 1.22016286e-04]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate predictions\n",
    "y_pred = logit.predict(x_train)\n",
    "y_pred_proba=logit.predict_proba(x_train)\n",
    "\n",
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate in-sample results using the model score, confusion matrix, and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression on training set: 0.96\n"
     ]
    }
   ],
   "source": [
    "# print model score\n",
    "print('Accuracy of Logistic regression on training set: {:.2f}'.format(logit.score(x_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0]\n",
      " [ 0 37  3]\n",
      " [ 0  1 32]]\n"
     ]
    }
   ],
   "source": [
    "# print confution martix\n",
    "\n",
    "print(confusion_matrix(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# confusion_matrix = confusion_matrix(y_train,y_pred)\n",
    "# # Sec calcs\n",
    "# FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "# FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "# TP = np.diag(confusion_matrix)\n",
    "# TN = confusion_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "# # Sensitivity, hit rate, recall, or true positive rate\n",
    "# TPR = TP/(TP+FN)\n",
    "# # Specificity or true negative rate\n",
    "# TNR = TN/(TN+FP) \n",
    "# # Precision or positive predictive value\n",
    "# PPV = TP/(TP+FP)\n",
    "# # Negative predictive value\n",
    "# NPV = TN/(TN+FN)\n",
    "# # Fall out or false positive rate\n",
    "# FPR = FP/(FP+TN)\n",
    "# # False negative rate\n",
    "# FNR = FN/(TP+FN)\n",
    "# # False discovery rate\n",
    "# FDR = FP/(TP+FP)\n",
    "\n",
    "# # Overall accuracy\n",
    "# ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setosa': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32},\n",
       " 'versicolor': {'precision': 0.9736842105263158,\n",
       "  'recall': 0.925,\n",
       "  'f1-score': 0.9487179487179489,\n",
       "  'support': 40},\n",
       " 'virginica': {'precision': 0.9142857142857143,\n",
       "  'recall': 0.9696969696969697,\n",
       "  'f1-score': 0.9411764705882354,\n",
       "  'support': 33},\n",
       " 'accuracy': 0.9619047619047619,\n",
       " 'macro avg': {'precision': 0.96265664160401,\n",
       "  'recall': 0.9648989898989898,\n",
       "  'f1-score': 0.9632981397687281,\n",
       "  'support': 105},\n",
       " 'weighted avg': {'precision': 0.9630361618331543,\n",
       "  'recall': 0.9619047619047619,\n",
       "  'f1-score': 0.9619765855059974,\n",
       "  'support': 105}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate classifiaction report\n",
    "cr=(classification_report(y_train,y_pred,output_dict=True))\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit data to regression to new solver\n",
    "logit=LogisticRegression(C=1,class_weight='balanced',random_state=123,solver='liblinear')\n",
    "logit.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.73154083e-04, 2.15635131e-01, 7.83491715e-01],\n",
       "       [8.97359857e-04, 1.76734891e-01, 8.22367749e-01],\n",
       "       [1.67572589e-02, 6.35328913e-01, 3.47913829e-01],\n",
       "       [8.96226906e-01, 1.03746789e-01, 2.63054825e-05],\n",
       "       [8.13687747e-01, 1.86187330e-01, 1.24922605e-04]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate predictions\n",
    "y_pred = logit.predict(x_train)\n",
    "y_pred_proba=logit.predict_proba(x_train)\n",
    "\n",
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0]\n",
      " [ 0 36  4]\n",
      " [ 0  1 32]]\n"
     ]
    }
   ],
   "source": [
    "# print confution martix\n",
    "print(confusion_matrix(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setosa': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32},\n",
       " 'versicolor': {'precision': 0.972972972972973,\n",
       "  'recall': 0.9,\n",
       "  'f1-score': 0.935064935064935,\n",
       "  'support': 40},\n",
       " 'virginica': {'precision': 0.8888888888888888,\n",
       "  'recall': 0.9696969696969697,\n",
       "  'f1-score': 0.927536231884058,\n",
       "  'support': 33},\n",
       " 'accuracy': 0.9523809523809523,\n",
       " 'macro avg': {'precision': 0.953953953953954,\n",
       "  'recall': 0.9565656565656565,\n",
       "  'f1-score': 0.9542003889829976,\n",
       "  'support': 105},\n",
       " 'weighted avg': {'precision': 0.9547833547833547,\n",
       "  'recall': 0.9523809523809523,\n",
       "  'f1-score': 0.9524885052835362,\n",
       "  'support': 105}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate classifiaction report\n",
    "cr=(classification_report(y_train,y_pred,output_dict=True))\n",
    "cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, \n",
    "\n",
    "false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "Run through steps 2-4 using entropy as your measure of impurity.\n",
    "\n",
    "Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydataset import data\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "1           5.1          3.5           1.4          0.2  setosa\n",
       "2           4.9          3.0           1.4          0.2  setosa\n",
       "3           4.7          3.2           1.3          0.2  setosa\n",
       "4           4.6          3.1           1.5          0.2  setosa\n",
       "5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get fresh iris data \n",
    "df_iris=data('iris')\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace . with _ in colomns\n",
    "df_iris.columns=[col.lower().replace('.','_') for col in df_iris]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x and y data sets then split into test and train\n",
    "X=df_iris.drop(['species'],axis=1)\n",
    "y=df_iris[['species']]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.30,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create decition tree object\n",
    "clf=DecisionTreeClassifier(criterion='entropy',max_depth=3,random_state=123)\n",
    "# fit data to object\n",
    "clf.fit(X_train,y_train)\n",
    "# create predictions\n",
    "y_pred=clf.predict(X_train)\n",
    "y_pred_proba=clf.predict_proba(X_train)\n",
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression on training set: 0.95\n"
     ]
    }
   ],
   "source": [
    "# print model score\n",
    "print('Accuracy of Logistic regression on training set: {:.2f}'.format(logit.score(x_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setosa': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32},\n",
       " 'versicolor': {'precision': 0.9523809523809523,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.975609756097561,\n",
       "  'support': 40},\n",
       " 'virginica': {'precision': 1.0,\n",
       "  'recall': 0.9393939393939394,\n",
       "  'f1-score': 0.96875,\n",
       "  'support': 33},\n",
       " 'accuracy': 0.9809523809523809,\n",
       " 'macro avg': {'precision': 0.9841269841269842,\n",
       "  'recall': 0.9797979797979798,\n",
       "  'f1-score': 0.9814532520325203,\n",
       "  'support': 105},\n",
       " 'weighted avg': {'precision': 0.981859410430839,\n",
       "  'recall': 0.9809523809523809,\n",
       "  'f1-score': 0.9808870499419281,\n",
       "  'support': 105}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate classifiaction report\n",
    "cr=(classification_report(y_train,y_pred,output_dict=True))\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32,  0,  0],\n",
       "       [ 0, 40,  0],\n",
       "       [ 0,  2, 31]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate confusion matrix\n",
    "confusion_matrix(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression on training set: 0.95\n"
     ]
    }
   ],
   "source": [
    "# print model score\n",
    "print('Accuracy of Logistic regression on training set: {:.2f}'.format(logit.score(x_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.975, 0.025],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create decition tree object\n",
    "clf=DecisionTreeClassifier(criterion='gini',max_depth=3,random_state=123)\n",
    "# fit data to object\n",
    "clf.fit(X_train,y_train)\n",
    "# create predictions\n",
    "y_pred=clf.predict(X_train)\n",
    "y_pred_proba=clf.predict_proba(X_train)\n",
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression on training set: 0.95\n"
     ]
    }
   ],
   "source": [
    "# print model score\n",
    "print('Accuracy of Logistic regression on training set: {:.2f}'.format(logit.score(x_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# object \n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=20, \n",
    "                            random_state=123)\n",
    "# train\n",
    "rf.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08980597 0.0198138  0.44366243 0.44671781]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate survive or not\n",
    "y_pred = rf.predict(x_train)\n",
    "# estimate probability of survival\n",
    "y_pred_proba = rf.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'.format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0]\n",
      " [ 0 40  0]\n",
      " [ 0  0 33]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        32\n",
      "  versicolor       1.00      1.00      1.00        40\n",
      "   virginica       1.00      1.00      1.00        33\n",
      "\n",
      "    accuracy                           1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=5,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)\n",
    "\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08647229 0.00786147 0.45520172 0.45046453]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate survive or not\n",
    "y_pred = rf.predict(x_train)\n",
    "# estimate probability of survival\n",
    "y_pred_proba = rf.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'.format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        32\n",
      "  versicolor       0.97      0.93      0.95        40\n",
      "   virginica       0.91      0.97      0.94        33\n",
      "\n",
      "    accuracy                           0.96       105\n",
      "   macro avg       0.96      0.96      0.96       105\n",
      "weighted avg       0.96      0.96      0.96       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0]\n",
      " [ 0 37  3]\n",
      " [ 0  1 32]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model is 100% accurate and likely overfit\n",
    "\n",
    "Second model is 96% accurate and likely the better choice due to not being over fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)**\n",
    "\n",
    "**Evaluate your results using the model score, confusion matrix, and classification report.**\n",
    "\n",
    "**Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.**\n",
    "\n",
    "**Run through steps 2-4 setting k to 10**\n",
    "\n",
    "**Run through setps 2-4 setting k to 20**\n",
    "\n",
    "**What are the differences in the evaluation metrics? Which performs better on your in-sample data? \n",
    "Why? TestFor both the iris and the titanic data,**\n",
    "\n",
    "**Determine which model (with hyperparameters) performs the best (try reducing the number of features to the top 4 features in terms of information gained for each feature individually).\n",
    "Create a new dataframe with top 4 features.**\n",
    "\n",
    "**Use the top performing algorithm with the metaparameters used in that model. Create the object, fit, transform on in-sample data, and evaluate the results with the training data. Compare your evaluation metrics with those from the original model (with all the features).**\n",
    "\n",
    "**Run your final model on your out-of-sample dataframe (test_df). Evaluate the results.**\n",
    "\n",
    "**Titanic Data\n",
    "Create a feature named who, this should be either man, woman, or child. How does including this feature affect your model's performance?**\n",
    "\n",
    "**Create a feature named adult_male that is either a 1 or a 0. How does this affect your model's predictions?**\n",
    "\n",
    "**Iris Data\n",
    "Create features named petal_area and sepal_area.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create object\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "# fit data to object\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08647229 0.00786147 0.45520172 0.45046453]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate survive or not\n",
    "y_pred = rf.predict(x_train)\n",
    "# estimate probability of survival\n",
    "y_pred_proba = rf.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'.format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0]\n",
      " [ 0 37  3]\n",
      " [ 0  1 32]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        32\n",
      "  versicolor       0.97      0.93      0.95        40\n",
      "   virginica       0.91      0.97      0.94        33\n",
      "\n",
      "    accuracy                           0.96       105\n",
      "   macro avg       0.96      0.96      0.96       105\n",
      "weighted avg       0.96      0.96      0.96       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create object\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "# fit data to object\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.97\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'.format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0]\n",
      " [ 0 37  3]\n",
      " [ 0  1 32]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        32\n",
      "  versicolor       0.97      0.93      0.95        40\n",
      "   virginica       0.91      0.97      0.94        33\n",
      "\n",
      "    accuracy                           0.96       105\n",
      "   macro avg       0.96      0.96      0.96       105\n",
      "weighted avg       0.96      0.96      0.96       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=20, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create object\n",
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "# fit data to object\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'.format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0]\n",
      " [ 0 37  3]\n",
      " [ 0  1 32]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        32\n",
      "  versicolor       0.97      0.93      0.95        40\n",
      "   virginica       0.91      0.97      0.94        33\n",
      "\n",
      "    accuracy                           0.96       105\n",
      "   macro avg       0.96      0.96      0.96       105\n",
      "weighted avg       0.96      0.96      0.96       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Range in accuracy from lowest model to the highest is .02\n",
    "\n",
    ".96 model least risk of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which model (with hyperparameters) performs the best (try reducing the number of features to the top 4 features in terms of information gained for each feature individually).\n",
    "\n",
    "Create a new dataframe with top 4 features.\n",
    "\n",
    "Use the top performing algorithm with the metaparameters used in that model. Create the object, fit, transform on in-sample data, and evaluate the results with the training data. Compare your evaluation metrics with those from the original model (with all the features).\n",
    "\n",
    "Run your final model on your out-of-sample dataframe (test_df). Evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create object\n",
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "# fit data to object\n",
    "knn.fit(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on test set: {:.2f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    scores.append(knn.score(x_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
