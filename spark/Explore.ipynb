{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different cases are there, by department?\n",
    "\n",
    "Does the percentage of cases that are late vary by department?\n",
    "\n",
    "On average, how late are the late cases by department?\n",
    "\n",
    "What is the service type that is the most late? Just for Parks & Rec?\n",
    "\n",
    "For the DSD/Code Enforcement department, what are the most common service request types? Look at other departments too.\n",
    "\n",
    "Does whether or not its a weekend matter for when a case is opened/closed?\n",
    "\n",
    "On average, how many cases are opened a day for the Customer Service department?\n",
    "\n",
    "Does the number of service requests for the solid waste department vary by day of the week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.10.17.164:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11acafc18>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "department = spark.read.csv(\"dept_copy.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "source = spark.read.csv(\"source_copy.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "case = spark.read.csv(\"case_copy.csv\", sep=\",\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "        source\n",
    "        .join(case,\"source_id\",\"left\")\n",
    "        .join(department,\"dept_division\",\"left\")\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----------------+----------+----------------+----------------+------------+---------+-------------------+-----------+--------------------+----------+-----------+--------------------+----------------+--------------------+----------------------+-------------------+\n",
      "|   dept_division|source_id| source_username|   case_id|case_opened_date|case_closed_date|SLA_due_date|case_late|      num_days_late|case_closed|service_request_type|  SLA_days|case_status|     request_address|council_district|           dept_name|standardized_dept_name|dept_subject_to_SLA|\n",
      "+----------------+---------+----------------+----------+----------------+----------------+------------+---------+-------------------+-----------+--------------------+----------+-----------+--------------------+----------------+--------------------+----------------------+-------------------+\n",
      "|Waste Collection|   136202|Michelle Urrutia|1014128056|     1/2/18 8:21|    1/10/18 8:39| 1/5/18 8:30|      YES|         5.00681713|        YES|Solid Waste Fees ...|3.00619213|     Closed|3214  STONEY FORK...|              10|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "|Waste Collection|   136202|Michelle Urrutia|1014128366|     1/2/18 9:36|    1/3/18 13:28| 1/9/18 9:36|       NO| -5.838321758999999|        YES|Cart Exchange Req...|       7.0|     Closed|11822  SONG, San ...|               9|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "|Waste Collection|   136202|Michelle Urrutia|1014128555|    1/2/18 10:07|    1/3/18 15:29|1/5/18 10:07|       NO|-1.7764930559999998|        YES|           No Pickup|       3.0|     Closed|13703  BLUFF ROCK...|               9|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "|Waste Collection|   136202|Michelle Urrutia|1014128764|    1/2/18 10:45|    1/8/18 13:58|1/9/18 10:45|       NO|       -0.865798611|        YES|Cart Exchange Req...|       7.0|     Closed|6270  RIDGEBROOK,...|               6|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "|Waste Collection|   136202|Michelle Urrutia|1014129021|    1/2/18 11:26|    1/3/18 14:08|1/9/18 11:26|       NO|       -5.887905093|        YES|Cart Exchange Req...|       7.0|     Closed|135  MAGNOLIA DR,...|               1|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "+----------------+---------+----------------+----------+----------------+----------------+------------+---------+-------------------+-----------+--------------------+----------+-----------+--------------------+----------------+--------------------+----------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different cases are there, by department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "all exprs should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b46972656898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardized_dept_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pyspark/sql/group.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# Columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all exprs should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             jdf = self._jgd.agg(exprs[0]._jc,\n\u001b[1;32m    115\u001b[0m                                 _to_seq(self.sql_ctx._sc, [c._jc for c in exprs[1:]]))\n",
      "\u001b[0;31mAssertionError\u001b[0m: all exprs should be Column"
     ]
    }
   ],
   "source": [
    "df.groupby(df.standardized_dept_name).agg(count(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
